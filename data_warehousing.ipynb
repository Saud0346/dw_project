{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c873f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just making copies of all the files\n",
    "import pandas as pd\n",
    "# Replace 'your_csv_file.csv' with the path to your CSV file\n",
    "csv_file = '/Users/saudahmad/desktop/archive (5)/data3.csv'\n",
    "new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/data3.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "data = pd.DataFrame(df)\n",
    "data.to_csv(new_csv_file, index=False)\n",
    "print(data.head(1))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "4f3f7b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/nj0lsj9j7p5d9n013793d8vh0000gn/T/ipykernel_32434/149976088.py:3: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(my_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[ True False]\n",
      "[False  True]\n",
      "[ True False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[ True]\n",
      "[ True]\n",
      "[False  True]\n",
      "////\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[ True False]\n",
      "[ True False]\n",
      "[ True False]\n",
      "[ True False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "////\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[ True False]\n",
      "[False]\n",
      "[False]\n",
      "[ True False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/nj0lsj9j7p5d9n013793d8vh0000gn/T/ipykernel_32434/149976088.py:32: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(my_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34660\n",
      "27900\n",
      "34658\n",
      "34660\n",
      "34660\n",
      "34660\n",
      "34660\n",
      "34621\n",
      "24039\n",
      "34660\n",
      "1\n",
      "34066\n",
      "1\n",
      "34131\n",
      "34627\n",
      "34660\n",
      "34659\n",
      "34655\n",
      "0\n",
      "0\n",
      "34658\n",
      "////\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "9\n",
      "16086\n",
      "41\n",
      "16115\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "28332\n",
      "////\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "1052\n",
      "5000\n",
      "5000\n",
      "29\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "4987\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #Searching for empty cells in a column\n",
    "my_csv = '/Users/saudahmad/desktop/archive (5)/update/data1.csv'\n",
    "df = pd.read_csv(my_csv)\n",
    "data1 = pd.DataFrame(df)\n",
    "for i in range(21):\n",
    "    print(data1.iloc[:,i].isnull().unique())\n",
    "print(\"////\")\n",
    "\n",
    "my_csv = '/Users/saudahmad/desktop/archive (5)/update/data2.csv'\n",
    "df = pd.read_csv(my_csv)\n",
    "data2 = pd.DataFrame(df)\n",
    "for i in range(24):\n",
    "    print(data2.iloc[:,i].isnull().unique())\n",
    "print(\"////\")\n",
    "\n",
    "my_csv = '/Users/saudahmad/desktop/archive (5)/update/data3.csv'\n",
    "df = pd.read_csv(my_csv)\n",
    "data3 = pd.DataFrame(df)\n",
    "for i in range(24):\n",
    "    print(data3.iloc[:,i].isnull().unique())\n",
    "\n",
    "\n",
    "# Putting zero on empty cells\n",
    "data1.fillna(0, inplace=True)  # Fills all NaN values with 0\n",
    "data2.fillna(0, inplace=True)  # Fills all NaN values with 0\n",
    "data3.fillna(0, inplace=True)  # Fills all NaN values with 0\n",
    "\n",
    "\n",
    "\n",
    "# Count of unuque elements in a row\n",
    "my_csv = '/Users/saudahmad/desktop/archive (5)/update/data1.csv'\n",
    "df = pd.read_csv(my_csv)\n",
    "data1 = pd.DataFrame(df)\n",
    "for i in range(21):\n",
    "    print(data1.iloc[:,i].count())\n",
    "print(\"////\")\n",
    "\n",
    "my_csv = '/Users/saudahmad/desktop/archive (5)/update/data2.csv'\n",
    "df = pd.read_csv(my_csv)\n",
    "data2 = pd.DataFrame(df)\n",
    "for i in range(24):\n",
    "    print(data2.iloc[:,i].count())\n",
    "print(\"////\")\n",
    "\n",
    "my_csv = '/Users/saudahmad/desktop/archive (5)/update/data3.csv'\n",
    "df = pd.read_csv(my_csv)\n",
    "data3 = pd.DataFrame(df)\n",
    "for i in range(24):\n",
    "    print(data3.iloc[:,i].count())\n",
    "\n",
    "# Eleminating empty rows\n",
    "data1 = data1.iloc[:,[0,1,2,3,4,5,6,7,8,9,11,13,14,15,16,17,20]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "310ebef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/nj0lsj9j7p5d9n013793d8vh0000gn/T/ipykernel_32434/4205027485.py:4: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(new_csv_file)\n"
     ]
    }
   ],
   "source": [
    "# Now lets break the data into facts and dimensions\n",
    "# For Fact1\n",
    "new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/data1.csv'\n",
    "df = pd.read_csv(new_csv_file)\n",
    "data = pd.DataFrame(df)\n",
    "fact1 = data[['id', 'asins', 'keys', 'reviews.date', 'reviews.dateAdded','reviews.didPurchase','reviews.dateSeen', 'reviews.doRecommend',\n",
    "             'reviews.id', 'reviews.numHelpful', 'reviews.rating']]\n",
    "\n",
    "# For Dimension1\n",
    "columns_to_exclude = ['id', 'asins', 'keys', 'reviews.date', 'reviews.dateAdded','reviews.didPurchase','reviews.dateSeen', 'reviews.doRecommend',\n",
    "             'reviews.id', 'reviews.numHelpful', 'reviews.rating']\n",
    "dim1 = data.drop(columns=columns_to_exclude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "39c56a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For fact2\n",
    "new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/data2.csv'\n",
    "df = pd.read_csv(new_csv_file)\n",
    "data = pd.DataFrame(df)\n",
    "fact2 = data[['id', 'dateAdded', 'dateUpdated', 'asins', 'keys', 'manufacturerNumber', 'reviews.date',\n",
    "             'reviews.dateSeen', 'reviews.didPurchase', 'reviews.doRecommend','reviews.id','reviews.numHelpful','reviews.rating']]\n",
    "\n",
    "# For Dimension2\n",
    "columns_to_exclude = ['id', 'dateAdded', 'dateUpdated', 'asins', 'keys', 'manufacturerNumber', 'reviews.date',\n",
    "              'reviews.dateSeen','reviews.didPurchase','reviews.doRecommend','reviews.id','reviews.numHelpful','reviews.rating']\n",
    "dim2 = data.drop(columns=columns_to_exclude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6f4ee642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                    All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...\n",
       "brand                                                              Amazon\n",
       "categories              Electronics,iPad & Tablets,All Tablets,Fire Ta...\n",
       "manufacturer                                                       Amazon\n",
       "reviews.sourceURLs      http://reviews.bestbuy.com/3545/5620406/review...\n",
       "reviews.text            This product so far has not disappointed. My c...\n",
       "reviews.title                                                      Kindle\n",
       "reviews.userCity                                                      NaN\n",
       "reviews.userProvince                                                  NaN\n",
       "reviews.username                                                  Adapter\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "ebd5bb78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For fact3\n",
    "new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/data3.csv'\n",
    "df = pd.read_csv(new_csv_file)\n",
    "data = pd.DataFrame(df)\n",
    "fact3 = data[['id', 'dateAdded', 'dateUpdated', 'asins', 'keys', 'manufacturerNumber', 'reviews.date',\n",
    "             'reviews.dateSeen', 'reviews.dateAdded', 'reviews.doRecommend','reviews.id','reviews.numHelpful','reviews.rating']]\n",
    "\n",
    "# For Dimension3\n",
    "columns_to_exclude = ['id', 'dateAdded', 'dateUpdated', 'asins', 'keys', 'manufacturerNumber', 'reviews.date',\n",
    "             'reviews.dateSeen', 'reviews.dateAdded', 'reviews.doRecommend','reviews.id','reviews.numHelpful','reviews.rating']\n",
    "dim3 = data.drop(columns=columns_to_exclude)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "2b60b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change the columns name \n",
    "\n",
    "fact1.columns = ['id', 'asins', 'keys', 'reviews_date', 'reviews_dateAdded','reviews_didPurchase','reviews_dateSeen', 'reviews_doRecommend',\n",
    "             'reviews_id', 'reviews_numHelpful', 'reviews_rating']\n",
    "\n",
    "fact2.columns = ['id', 'dateAdded', 'dateUpdated', 'asins', 'keys', 'manufacturerNumber', 'reviews_date',\n",
    "                 'reviews_dateSeen', 'reviews_didPurchase', 'reviews_doRecommend','reviews_id','reviews_numHelpful','reviews_rating']\n",
    "\n",
    "fact3.columns = ['id', 'dateAdded', 'dateUpdated', 'asins', 'keys', 'manufacturerNumber', 'reviews_date',\n",
    "             'reviews_dateSeen', 'reviews_dateAdded', 'reviews_doRecommend','reviews_id','reviews_numHelpful','reviews_rating']\n",
    "\n",
    "dim1.columns = ['name', 'brand', 'categories','manufacturer', 'reviews_sourceURLs', 'reviews_text', 'reviews_title','reviews_userCity'\n",
    "       ,'reviews_userProvince','reviews_username']\n",
    "\n",
    "dim2.columns = ['name', 'brand', 'categories', 'primaryCategories', 'imageURLs','manufacturer', 'reviews_sourceURLs', 'reviews_text', 'reviews_title',\n",
    "       'reviews_username', 'sourceURLs']\n",
    "\n",
    "dim3.columns = ['name', 'brand', 'categories', 'primaryCategories', 'imageURLs','manufacturer', 'reviews_sourceURLs', 'reviews_text', 'reviews_title',\n",
    "       'reviews_username', 'sourceURLs']\n",
    "\n",
    "# print(dim3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "6458e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data to the already made csv files \n",
    "# new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/fact1.csv'\n",
    "# fact1.to_csv(new_csv_file, index=False)\n",
    "\n",
    "# new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/fact2.csv'\n",
    "# fact2.to_csv(new_csv_file, index=False)\n",
    "\n",
    "# new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/fact3.csv'\n",
    "# fact3.to_csv(new_csv_file, index=False)\n",
    "\n",
    "new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/dim1.csv'\n",
    "dim1.to_csv(new_csv_file, index=False)\n",
    "\n",
    "# new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/dim2.csv'\n",
    "# dim2.to_csv(new_csv_file, index=False)\n",
    "\n",
    "# new_csv_file = '/Users/saudahmad/desktop/archive (5)/update/dim3.csv'\n",
    "# dim3.to_csv(new_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "29bf1f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34660, 10)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To load data to their respective tables\n",
    "dim1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "cfbed0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Example: Creating a DataFrame (this should be replaced with your actual data source)\n",
    "# Replace 'path_to_your_csv_file.csv' with the path to your CSV file\n",
    "csv_file = '/Users/saudahmad/Desktop/archive (5)/update/dim1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Connect to the MySQL database\n",
    "try:\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',       # or the hostname of your MySQL server\n",
    "        user='root',            # your MySQL username\n",
    "        passwd='12345678',      # your MySQL password\n",
    "        database='staging_area'         # the database you want to connect to\n",
    "    )\n",
    "\n",
    "    # Insert data from the DataFrame into the MySQL table\n",
    "    if connection is not None and connection.is_connected():\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "    # Enclose column names in backticks to handle reserved words and special characters\n",
    "    cols = ','.join([f'`{col}`' for col in df.columns])\n",
    "    placeholders = ','.join(['%s'] * len(df.columns))\n",
    "    sql = f\"INSERT INTO dim1 ({cols}) VALUES ({placeholders})\"\n",
    "\n",
    "    # Iterate over the rows and insert them into the database\n",
    "    for row in df.itertuples(index=False, name=None):\n",
    "        cursor.execute(sql, row)\n",
    "\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "except Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        connection.close()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0bad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "586c6736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/nj0lsj9j7p5d9n013793d8vh0000gn/T/ipykernel_32434/793248824.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df1 = pd.read_sql_query(sql_query1, conn)\n",
      "/var/folders/wl/nj0lsj9j7p5d9n013793d8vh0000gn/T/ipykernel_32434/793248824.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df2 = pd.read_sql_query(sql_query2, conn)\n",
      "/var/folders/wl/nj0lsj9j7p5d9n013793d8vh0000gn/T/ipykernel_32434/793248824.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df3 = pd.read_sql_query(sql_query3, conn)\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',       # or the hostname of your MySQL server\n",
    "    user='root',   # your MySQL username\n",
    "    passwd='12345678', # your MySQL password\n",
    "    database='my_warehouse' # the database you want to connect to\n",
    ")\n",
    "\n",
    "\n",
    "sql_query1 = \"select reviews_text from dim1\"\n",
    "sql_query2 = \"select reviews_text from dim2\"\n",
    "sql_query3 = \"select reviews_text from dim3\"\n",
    "\n",
    "\n",
    "# Use pandas to fetch the data into a DataFrame\n",
    "df1 = pd.read_sql_query(sql_query1, conn)\n",
    "df2 = pd.read_sql_query(sql_query2, conn)\n",
    "df3 = pd.read_sql_query(sql_query3, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "b74b29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.concat([df1, df2, df3], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "10f0f5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Useful for adults, educational and entertainin...</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>Didnt know how much i'd use a kindle so went f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We actually bought these for our summer camp p...</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>I thought it would be as big as small paper bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>Solid entry level Kindle. Great for kids. Gift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is an ok tablet. As I am using it, I lose m...</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>This kindle is light and easy to use especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>I am 100 happy with my purchase. I caught it o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews_text  \\\n",
       "0  Useful for adults, educational and entertainin...   \n",
       "1  We actually bought these for our summer camp p...   \n",
       "2  This product so far has not disappointed. My c...   \n",
       "3  It is an ok tablet. As I am using it, I lose m...   \n",
       "4  great for beginner or experienced person. Boug...   \n",
       "\n",
       "                                        reviews_text  \\\n",
       "0  I order 3 of them and one of the item is bad q...   \n",
       "1  Bulk is always the less expensive way to go fo...   \n",
       "2  Well they are not Duracell but for the price i...   \n",
       "3  Seem to work as well as name brand batteries a...   \n",
       "4  These batteries are very long lasting the pric...   \n",
       "\n",
       "                                        reviews_text  \n",
       "0  Didnt know how much i'd use a kindle so went f...  \n",
       "1  I thought it would be as big as small paper bu...  \n",
       "2  Solid entry level Kindle. Great for kids. Gift...  \n",
       "3  This kindle is light and easy to use especiall...  \n",
       "4  I am 100 happy with my purchase. I caught it o...  "
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "8d6adc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x14832f5d0>"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.tail()\n",
    "# 34659\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import sys,os\n",
    "\n",
    "\n",
    "text = open('/Users/saudahmad/Desktop/archive (5)/update/new/text.csv',mode='r',encoding ='utf_8').read()\n",
    "\n",
    "stopwords = STOPWORDS\n",
    "\n",
    "wc = WordCloud(\n",
    "    \n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords,\n",
    "    height = 1600,\n",
    "    width  = 2560\n",
    "       \n",
    "       )\n",
    "wc.generate(text)\n",
    "\n",
    "wc.to_file('word_cloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c55faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the PNG image\n",
    "image = Image.open('word_cloud.png')\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1eb9e3",
   "metadata": {},
   "source": [
    "df3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8690b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querries used till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to drop columns\n",
    "ALTER TABLE your_table\n",
    "DROP COLUMN column1,\n",
    "DROP COLUMN column2,\n",
    "DROP COLUMN column3;\n",
    "\n",
    "# to add a column(primary key) which will automatically increase \n",
    "ALTER TABLE your_table\n",
    "ADD id INT AUTO_INCREMENT PRIMARY KEY;\n",
    "\n",
    "# to rename a table\n",
    "RENAME TABLE your_table_copy TO your_table;\n",
    "\n",
    "# to delete a row\n",
    "DELETE FROM fact2 WHERE u_id2 = 1;\n",
    "\n",
    "# to make changes in a table we have to set this to 0\n",
    "SET SQL_SAFE_UPDATES = 0;\n",
    "\n",
    "# To transfer data from one data base to another\n",
    "CREATE TABLE target_db.employees AS\n",
    "SELECT *\n",
    "FROM source_db.employees;\n",
    "\n",
    "# To see the columns names\n",
    "SHOW COLUMNS FROM fact1;\n",
    "\n",
    "# Adding a foreign key constrain\n",
    "ALTER TABLE fact1\n",
    "ADD CONSTRAINT fk_fact2\n",
    "FOREIGN KEY (pk_fact2)\n",
    "REFERENCES fact2 (u_id2)\n",
    "\n",
    "# Dropping a foreign key constrain\n",
    "ALTER TABLE fact3\n",
    "DROP FOREIGN KEY fk_data3;\n",
    "\n",
    "\n",
    "# to make sure the unqueness of the key selected as foreign key\n",
    "ALTER TABLE dim3\n",
    "ADD UNIQUE INDEX idx_pk_dim3 (pk_dim3);\n",
    "# to undo the above query \n",
    "DROP INDEX idx_pk_dim1 ON dim2;\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
